{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "07e53caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import requests\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from parsivar import Tokenizer, Normalizer\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fc31cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    \"اجتماعی\" : \"social\",\n",
    "    \"اديان\" : \"religion\",\n",
    "    \"اقتصادی\" : \"economics\",\n",
    "    \"سیاسی\" : \"politics\",\n",
    "    \"فناوري\" : \"technology\" ,\n",
    "    \"مسائل راهبردي ايران\" : \"strategic\" ,\n",
    "    \"ورزشی\" : \"sport\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c076993",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian = requests.get('https://raw.githubusercontent.com/kharazi/persian-stopwords/master/persian').text.split('\\n')\n",
    "verbal = requests.get('https://raw.githubusercontent.com/kharazi/persian-stopwords/master/verbal').text.split('\\n')\n",
    "nonverbal = requests.get('https://raw.githubusercontent.com/kharazi/persian-stopwords/master/nonverbal').text.split('\\n')\n",
    "\n",
    "stop_words = persian + verbal + nonverbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6fde6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "train_labels = []\n",
    "\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "\n",
    "def extract_texts (root, label , file, is_train) :\n",
    "    path = root + '/' + file \n",
    "    with open(path,'r',encoding=\"utf-8\") as f : \n",
    "        text = f.read()\n",
    "        \n",
    "        if is_train :\n",
    "            train_texts.append(text)\n",
    "            train_labels.append(LABELS[label])\n",
    "        else :\n",
    "            test_texts.append(text)\n",
    "            test_labels.append(LABELS[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "33613f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root,dirs,files) in os.walk('./Final_Dataset/Train') :\n",
    "    \n",
    "    if len(files) == 0 :\n",
    "        continue\n",
    "    for f in files :\n",
    "        label = root.split('\\\\')[1]\n",
    "        extract_texts(root,label,f, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9964fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['text'] = train_texts \n",
    "train['label'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c74dd55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿  به گزارش ايسنا، مهندس خرم، وزير راه و ترابر...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به گزارش خبرنگار اجتماعي خبرگزاري دانشجويان ...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دكتر امان‌الله قرايي‌مقدم، عضو هيات علمي دان...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به گزارش خبرنگار پارلماني ايسنا، در اين گزار...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>به گزارش ايسنا، معاون اجتماعي وزير كشور معتق...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  ﻿  به گزارش ايسنا، مهندس خرم، وزير راه و ترابر...  social\n",
       "1    به گزارش خبرنگار اجتماعي خبرگزاري دانشجويان ...  social\n",
       "2    دكتر امان‌الله قرايي‌مقدم، عضو هيات علمي دان...  social\n",
       "3    به گزارش خبرنگار پارلماني ايسنا، در اين گزار...  social\n",
       "4    به گزارش ايسنا، معاون اجتماعي وزير كشور معتق...  social"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4364643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root,dirs,files) in os.walk('./Final_Dataset/Test') :\n",
    "    \n",
    "    if len(files) == 0 :\n",
    "        continue\n",
    "    for f in files :\n",
    "        label = root.split('\\\\')[1]\n",
    "        \n",
    "        extract_texts(root,label,f, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0785ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['text'] = test_texts \n",
    "test['label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4e46634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿  شهردار تهران شب گذشته در برنامه زنده تلويزي...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿  معاون پرورشي و تربيت بدني وزارت آموزش و پرو...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حجت الاسلام والمسلمين سيد محمد رضا غياثي کرم...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سمينار \"اسلام و آينده و نسل جديد\" 24 آذرماه ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ماده 69 قانون برنامه پنجم به موضوع بهره‌وري ...</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>﻿  به گزارش خبرگزاري دانشجويان ايران (ايسنا) ا...</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>به گزارش خبرنگار سياسي ايسنا،‌ محمدي در ابتد...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>﻿  خبرگزاري دانشجويان ايران نيز در راستاي منوي...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>مجري پروژ‌ه‌هاي ملي و طرح ucf اصفهان معتقد ا...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>﻿  بر اساس برنامه اعلام شده توسط سازمان فضايي ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>﻿  اشاره: در ويرايش نخست &amp;amp;nbsp;اولين بخش &amp;...</td>\n",
       "      <td>strategic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>اشاره: آن‌چه &amp;amp;nbsp; در پي مي‌آيد، لينك &amp;...</td>\n",
       "      <td>strategic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>سرپرست باشگاه پرسپوليس دوشنبه ميهمان خبرگزار...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>به گزارش خبرگزاري دانشجويان ايران (ايسنا)، ع...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text       label\n",
       "0   ﻿  شهردار تهران شب گذشته در برنامه زنده تلويزي...      social\n",
       "1   ﻿  معاون پرورشي و تربيت بدني وزارت آموزش و پرو...      social\n",
       "2     حجت الاسلام والمسلمين سيد محمد رضا غياثي کرم...    religion\n",
       "3     سمينار \"اسلام و آينده و نسل جديد\" 24 آذرماه ...    religion\n",
       "4     ماده 69 قانون برنامه پنجم به موضوع بهره‌وري ...   economics\n",
       "5   ﻿  به گزارش خبرگزاري دانشجويان ايران (ايسنا) ا...   economics\n",
       "6     به گزارش خبرنگار سياسي ايسنا،‌ محمدي در ابتد...    politics\n",
       "7   ﻿  خبرگزاري دانشجويان ايران نيز در راستاي منوي...    politics\n",
       "8     مجري پروژ‌ه‌هاي ملي و طرح ucf اصفهان معتقد ا...  technology\n",
       "9   ﻿  بر اساس برنامه اعلام شده توسط سازمان فضايي ...  technology\n",
       "10  ﻿  اشاره: در ويرايش نخست &amp;nbsp;اولين بخش &...   strategic\n",
       "11    اشاره: آن‌چه &amp;nbsp; در پي مي‌آيد، لينك &...   strategic\n",
       "12    سرپرست باشگاه پرسپوليس دوشنبه ميهمان خبرگزار...       sport\n",
       "13    به گزارش خبرگزاري دانشجويان ايران (ايسنا)، ع...       sport"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ed4b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_punctuation = punctuation + '،\"؛«»)\\('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b331946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "58d99e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text (text, remove_stop_words=True) :\n",
    "    tokens = tokenizer.tokenize_words(normalizer.normalize(text))\n",
    "    if remove_stop_words :\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join([word for word in tokens if word not in list(my_punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7bef74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:].text = train.text.apply(normalize_text, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9bdb6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:].text = test.text.apply(normalize_text, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c44e866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = defaultdict(int)\n",
    "\n",
    "def count_tokens (text) :\n",
    "    words = tokenizer.tokenize_words(text) \n",
    "    for word in words : \n",
    "        tokens[word] += 1 \n",
    "        \n",
    "train.text.apply(count_tokens )\n",
    "test.text.apply(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "378f8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dict(sorted(tokens.items(), key=lambda item: item[1], reverse=True)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1c65be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_keys = list(tokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a6be945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = []\n",
    "for row in train.loc[:].values :\n",
    "    text = row[0]\n",
    "    label = row[1] \n",
    "    words = tokenizer.tokenize_words(text) \n",
    "    new_record = {token : words.count(token) for token in token_keys}\n",
    "    new_record.update({'label':label})\n",
    "    train_vectors.append(new_record)\n",
    "    \n",
    "train_vectors = pd.DataFrame.from_dict(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9daf3ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 501)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "a105d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "for row in test.loc[:].values :\n",
    "    text = row[0]\n",
    "    label = row[1] \n",
    "    words = tokenizer.tokenize_words(text) \n",
    "    new_record = {token : words.count(token) for token in token_keys}\n",
    "    new_record.update({'label':label})\n",
    "    test_vectors.append(new_record)\n",
    "    \n",
    "test_vectors = pd.DataFrame.from_dict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c8434909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 501)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2d384d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy=False,with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "4173dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_train_vectors = scaler.fit_transform(train_vectors.drop('label',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f5b76130",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test , y_train,y_test = train_test_split(standard_train_vectors, train_vectors.label, test_size=0.3 , \\\n",
    "                                                  random_state=101, stratify=train_vectors.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2357329",
   "metadata": {},
   "source": [
    "# Using Multinomial Naive Bayes for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "73f6e7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ef570d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "293bbfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   economics       0.50      0.50      0.50         2\n",
      "    politics       0.67      0.67      0.67         3\n",
      "    religion       1.00      1.00      1.00         2\n",
      "      social       0.00      0.00      0.00         3\n",
      "       sport       1.00      1.00      1.00         2\n",
      "   strategic       1.00      0.50      0.67         2\n",
      "  technology       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.66      0.67      0.63        17\n",
      "weighted avg       0.61      0.65      0.60        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\university\\isfahan uni\\simester 8\\data_mining\\project_final\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\university\\isfahan uni\\simester 8\\data_mining\\project_final\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\university\\isfahan uni\\simester 8\\data_mining\\project_final\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "12c41664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "5091df14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470588235294118"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "4622847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ad202909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333333333333332"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4cfcb",
   "metadata": {},
   "source": [
    "# Using KNN algorithm for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "0feb1e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "accuracy = 0.4117647058823529\n",
      "recall = 0.40476190476190477\n",
      "f1_score = 0.38095238095238093\n",
      "[[1 0 0 1 0 0 0]\n",
      " [0 0 1 1 0 1 0]\n",
      " [0 0 1 1 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0]\n",
      " [0 0 0 2 0 0 1]]\n",
      "----------\n",
      "K = 3\n",
      "accuracy = 0.17647058823529413\n",
      "recall = 0.21428571428571427\n",
      "f1_score = 0.13333333333333333\n",
      "[[0 0 1 0 0 1 0]\n",
      " [0 0 2 1 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [1 0 2 0 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]]\n",
      "----------\n",
      "K = 5\n",
      "accuracy = 0.23529411764705882\n",
      "recall = 0.2857142857142857\n",
      "f1_score = 0.20476190476190476\n",
      "[[1 0 1 0 0 0 0]\n",
      " [0 0 2 0 0 1 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [1 0 2 0 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]]\n",
      "----------\n",
      "K = 15\n",
      "accuracy = 0.35294117647058826\n",
      "recall = 0.35714285714285715\n",
      "f1_score = 0.3154761904761904\n",
      "[[1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 3]\n",
      " [0 0 1 0 0 0 1]\n",
      " [1 0 0 0 0 0 2]\n",
      " [0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 3]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ks = [1,3,5,15]\n",
    "for k in ks:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k )\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    print(f'K = {k}')\n",
    "    print(f'accuracy = {accuracy_score(y_test,y_pred)}')\n",
    "    print(f\"recall = {recall_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"f1_score = {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6bc93",
   "metadata": {},
   "source": [
    "# Calculating TF-IDF for tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "24c1c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_tokens = defaultdict(int)\n",
    "num_of_all_texts = train.shape[0] + test.shape[0]\n",
    "for key,value in tokens.items() :\n",
    "    idf = sum(train.text.apply(lambda text : 1 if key in text else 0 ))\n",
    "    idf += sum(test.text.apply(lambda text : 1 if key in text else 0 ))\n",
    "    idf = math.log10(num_of_all_texts / idf)\n",
    "    \n",
    "    tfidf_tokens[key] =  idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d70297c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_by_tfidf (vector) :\n",
    "    l = []\n",
    "    for key, value in zip(vector.index,vector.values) :\n",
    "        l.append(value * tfidf_tokens[key])\n",
    "    \n",
    "    return l\n",
    "\n",
    "\n",
    "train_labels = train_vectors.label\n",
    "train_vectors = pd.DataFrame.from_records(train_vectors.drop('label',axis=1).apply(replace_by_tfidf,axis=1), columns= list(train_vectors.columns).remove('label'))\n",
    "train_vectors['label'] = train_labels\n",
    "\n",
    "test_labels = test_vectors.label\n",
    "test_vectors = pd.DataFrame.from_records(test_vectors.drop('label', axis=1).apply(replace_by_tfidf, axis=1), columns = list(test_vectors.columns).remove('label'))\n",
    "test_vectors['label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "10b8ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test ,y_trian,y_test = train_test_split(train_vectors.drop('label', axis=1), train_vectors.label, test_size=0.3, \\\n",
    "                                                 random_state=101, stratify=train_vectors.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "d6be7783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "accuracy = 0.4117647058823529\n",
      "recall = 0.4285714285714285\n",
      "f1_score = 0.35634920634920636\n",
      "[[0 0 1 0 0 0 1]\n",
      " [0 0 0 1 0 0 2]\n",
      " [0 0 2 0 0 0 0]\n",
      " [1 0 0 1 0 0 1]\n",
      " [0 0 0 0 2 0 0]\n",
      " [0 0 0 2 0 0 0]\n",
      " [0 0 0 1 0 0 2]]\n",
      "----------\n",
      "K = 3\n",
      "accuracy = 0.29411764705882354\n",
      "recall = 0.33333333333333337\n",
      "f1_score = 0.25824175824175827\n",
      "[[1 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 2]\n",
      " [0 0 2 0 0 0 0]\n",
      " [1 0 2 0 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 2 0 0 0 1]]\n",
      "----------\n",
      "K = 5\n",
      "accuracy = 0.29411764705882354\n",
      "recall = 0.33333333333333337\n",
      "f1_score = 0.2857142857142857\n",
      "[[1 0 1 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 0 0 1 0 1]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 2 0 0 0 1]]\n",
      "----------\n",
      "K = 15\n",
      "accuracy = 0.29411764705882354\n",
      "recall = 0.2857142857142857\n",
      "f1_score = 0.19999999999999998\n",
      "[[1 0 0 0 0 0 1]\n",
      " [2 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 2]\n",
      " [1 0 0 0 0 0 2]\n",
      " [0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 3]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ks = [1,3,5,15]\n",
    "for k in ks:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k )\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    print(f'K = {k}')\n",
    "    print(f'accuracy = {accuracy_score(y_test,y_pred)}')\n",
    "    print(f\"recall = {recall_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"f1_score = {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c462c",
   "metadata": {},
   "source": [
    "If set remove_stop_words parameter to **True** in *normalize_text* method we can see that performance of both KNN and naive bayes models will increase!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
