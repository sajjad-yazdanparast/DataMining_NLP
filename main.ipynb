{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07e53caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import requests\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from parsivar import Tokenizer, Normalizer, FindStems\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ab1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    \"اجتماعی\" : \"social\",\n",
    "    \"اديان\" : \"religion\",\n",
    "    \"اقتصادی\" : \"economics\",\n",
    "    \"سیاسی\" : \"politics\",\n",
    "    \"فناوري\" : \"technology\" ,\n",
    "    \"مسائل راهبردي ايران\" : \"strategic\" ,\n",
    "    \"ورزشی\" : \"sport\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e2481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian = requests.get('https://raw.githubusercontent.com/kharazi/persian-stopwords/master/persian').text.split('\\n')\n",
    "verbal = requests.get('https://raw.githubusercontent.com/kharazi/persian-stopwords/master/verbal').text.split('\\n')\n",
    "nonverbal = requests.get('https://raw.githubusercontent.com/kharazi/persian-stopwords/master/nonverbal').text.split('\\n')\n",
    "\n",
    "stop_words = persian + verbal + nonverbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fde6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "train_labels = []\n",
    "\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "\n",
    "def extract_texts (root, label , file, is_train) :\n",
    "    path = root + '/' + file \n",
    "    with open(path,'r',encoding=\"utf-8\") as f : \n",
    "        text = f.read()\n",
    "        \n",
    "        if is_train :\n",
    "            train_texts.append(text)\n",
    "            train_labels.append(LABELS[label])\n",
    "        else :\n",
    "            test_texts.append(text)\n",
    "            test_labels.append(LABELS[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33613f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root,dirs,files) in os.walk('./Final_Dataset/Train') :\n",
    "    \n",
    "    if len(files) == 0 :\n",
    "        continue\n",
    "    for f in files :\n",
    "        label = root.split('\\\\')[1]\n",
    "        extract_texts(root,label,f, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9964fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['text'] = train_texts \n",
    "train['label'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c74dd55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿  به گزارش ايسنا، مهندس خرم، وزير راه و ترابر...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به گزارش خبرنگار اجتماعي خبرگزاري دانشجويان ...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دكتر امان‌الله قرايي‌مقدم، عضو هيات علمي دان...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به گزارش خبرنگار پارلماني ايسنا، در اين گزار...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>به گزارش ايسنا، معاون اجتماعي وزير كشور معتق...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  ﻿  به گزارش ايسنا، مهندس خرم، وزير راه و ترابر...  social\n",
       "1    به گزارش خبرنگار اجتماعي خبرگزاري دانشجويان ...  social\n",
       "2    دكتر امان‌الله قرايي‌مقدم، عضو هيات علمي دان...  social\n",
       "3    به گزارش خبرنگار پارلماني ايسنا، در اين گزار...  social\n",
       "4    به گزارش ايسنا، معاون اجتماعي وزير كشور معتق...  social"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bfe715",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root,dirs,files) in os.walk('./Final_Dataset/Test') :\n",
    "    \n",
    "    if len(files) == 0 :\n",
    "        continue\n",
    "    for f in files :\n",
    "        label = root.split('\\\\')[1]\n",
    "        \n",
    "        extract_texts(root,label,f, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0785ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['text'] = test_texts \n",
    "test['label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e46634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿  شهردار تهران شب گذشته در برنامه زنده تلويزي...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿  معاون پرورشي و تربيت بدني وزارت آموزش و پرو...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>حجت الاسلام والمسلمين سيد محمد رضا غياثي کرم...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سمينار \"اسلام و آينده و نسل جديد\" 24 آذرماه ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ماده 69 قانون برنامه پنجم به موضوع بهره‌وري ...</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>﻿  به گزارش خبرگزاري دانشجويان ايران (ايسنا) ا...</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>به گزارش خبرنگار سياسي ايسنا،‌ محمدي در ابتد...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>﻿  خبرگزاري دانشجويان ايران نيز در راستاي منوي...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>مجري پروژ‌ه‌هاي ملي و طرح ucf اصفهان معتقد ا...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>﻿  بر اساس برنامه اعلام شده توسط سازمان فضايي ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>﻿  اشاره: در ويرايش نخست &amp;amp;nbsp;اولين بخش &amp;...</td>\n",
       "      <td>strategic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>اشاره: آن‌چه &amp;amp;nbsp; در پي مي‌آيد، لينك &amp;...</td>\n",
       "      <td>strategic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>سرپرست باشگاه پرسپوليس دوشنبه ميهمان خبرگزار...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>به گزارش خبرگزاري دانشجويان ايران (ايسنا)، ع...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text       label\n",
       "0   ﻿  شهردار تهران شب گذشته در برنامه زنده تلويزي...      social\n",
       "1   ﻿  معاون پرورشي و تربيت بدني وزارت آموزش و پرو...      social\n",
       "2     حجت الاسلام والمسلمين سيد محمد رضا غياثي کرم...    religion\n",
       "3     سمينار \"اسلام و آينده و نسل جديد\" 24 آذرماه ...    religion\n",
       "4     ماده 69 قانون برنامه پنجم به موضوع بهره‌وري ...   economics\n",
       "5   ﻿  به گزارش خبرگزاري دانشجويان ايران (ايسنا) ا...   economics\n",
       "6     به گزارش خبرنگار سياسي ايسنا،‌ محمدي در ابتد...    politics\n",
       "7   ﻿  خبرگزاري دانشجويان ايران نيز در راستاي منوي...    politics\n",
       "8     مجري پروژ‌ه‌هاي ملي و طرح ucf اصفهان معتقد ا...  technology\n",
       "9   ﻿  بر اساس برنامه اعلام شده توسط سازمان فضايي ...  technology\n",
       "10  ﻿  اشاره: در ويرايش نخست &amp;nbsp;اولين بخش &...   strategic\n",
       "11    اشاره: آن‌چه &amp;nbsp; در پي مي‌آيد، لينك &...   strategic\n",
       "12    سرپرست باشگاه پرسپوليس دوشنبه ميهمان خبرگزار...       sport\n",
       "13    به گزارش خبرگزاري دانشجويان ايران (ايسنا)، ع...       sport"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_punctuation = punctuation + '،\"؛«»)\\('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b331946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "normalizer = Normalizer()\n",
    "stemmer = FindStems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58d99e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text (text, remove_stop_words=True) :\n",
    "    text = text.replace(\"nbsp\", \" \")\n",
    "    text = text.replace(\"amp\", \" \")\n",
    "    text = text.replace(\"ي\", \"ی\")\n",
    "    text = text.replace('ك', 'ک')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    \n",
    "    tokens = tokenizer.tokenize_words(normalizer.normalize(text))\n",
    "    if remove_stop_words :\n",
    "        tokens = [stemmer.convert_to_stem(word).split('&')[0] for word in tokens if word not in stop_words]\n",
    "    return ' '.join([word for word in tokens if word not in list(my_punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7bef74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:].text = train.text.apply(normalize_text, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "deb92867",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:].text = test.text.apply(normalize_text, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c44e866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = defaultdict(int)\n",
    "\n",
    "def count_tokens (text) :\n",
    "    words = tokenizer.tokenize_words(text) \n",
    "    for word in words : \n",
    "        tokens[word] += 1 \n",
    "        \n",
    "train.text.apply(count_tokens )\n",
    "test.text.apply(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "378f8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dict(sorted(tokens.items(), key=lambda item: item[1], reverse=True)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e6da107",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_keys = list(tokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5113a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = []\n",
    "for row in train.loc[:].values :\n",
    "    text = row[0]\n",
    "    label = row[1] \n",
    "    words = tokenizer.tokenize_words(text) \n",
    "    new_record = {token : words.count(token) for token in token_keys}\n",
    "    new_record.update({'label':label})\n",
    "    train_vectors.append(new_record)\n",
    "    \n",
    "train_vectors = pd.DataFrame.from_dict(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "343e301d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['کشور',\n",
       " 'طرح',\n",
       " 'سال',\n",
       " 'ایران',\n",
       " 'کار',\n",
       " 'دین',\n",
       " 'سیاسی',\n",
       " 'ادامه',\n",
       " 'تهران',\n",
       " 'اسلامی',\n",
       " 'قرار',\n",
       " 'جامعه',\n",
       " 'دولت',\n",
       " 'توجه',\n",
       " 'تیم',\n",
       " 'گفت\\u200cوگو',\n",
       " 'نظر',\n",
       " 'دانشگاه',\n",
       " 'سازمان',\n",
       " 'ماه',\n",
       " 'توسعه',\n",
       " 'برنامه',\n",
       " 'امام',\n",
       " 'اجتماعی',\n",
       " 'ملی',\n",
       " 'بانک',\n",
       " 'دکتر',\n",
       " 'اشاره',\n",
       " 'ایسنا',\n",
       " 'دانشجو',\n",
       " 'ایجاد',\n",
       " 'تاکید',\n",
       " 'شورا',\n",
       " 'بیان',\n",
       " 'شرایط',\n",
       " 'اقتصادی',\n",
       " 'گزارش',\n",
       " 'جامع',\n",
       " 'افزایش',\n",
       " 'اظهار',\n",
       " 'خبرنگار',\n",
       " 'فوتبال',\n",
       " 'فعالیت',\n",
       " 'درصد',\n",
       " 'عضو',\n",
       " 'اسلام',\n",
       " 'افراد',\n",
       " 'دست',\n",
       " 'نسبت',\n",
       " 'منطقه',\n",
       " 'تقوا',\n",
       " 'مسوول',\n",
       " 'حزب',\n",
       " 'باشگاه',\n",
       " 'مسائل',\n",
       " 'پرداخت',\n",
       " 'بازی',\n",
       " 'تومان',\n",
       " 'سیاست',\n",
       " 'حضور',\n",
       " 'بحث',\n",
       " 'انقلاب',\n",
       " 'تصریح',\n",
       " 'شهر',\n",
       " 'مساله',\n",
       " 'نظام',\n",
       " 'دلیل',\n",
       " 'شرکت',\n",
       " 'قانون',\n",
       " 'قیمت',\n",
       " 'این\\u200cکه',\n",
       " 'تولید',\n",
       " 'منبع',\n",
       " 'علمی',\n",
       " 'دینی',\n",
       " 'جهانی',\n",
       " 'بررسی',\n",
       " 'گروه',\n",
       " 'مهم',\n",
       " 'نیاز',\n",
       " 'نفت',\n",
       " 'پاسخ',\n",
       " 'انرژی',\n",
       " 'دان',\n",
       " 'عامل',\n",
       " 'هیات',\n",
       " 'موضوع',\n",
       " 'رمضان',\n",
       " 'مجلس',\n",
       " 'فرهنگی',\n",
       " 'ملت',\n",
       " 'بازیکن',\n",
       " 'رابطه',\n",
       " 'نتیجه',\n",
       " 'کشاورزی',\n",
       " 'عمومی',\n",
       " 'مدیریت',\n",
       " 'اجرا',\n",
       " 'حوزه',\n",
       " 'فضا',\n",
       " 'رسید',\n",
       " 'ماده',\n",
       " 'مدیر',\n",
       " 'آینده',\n",
       " 'دید',\n",
       " 'پروژه',\n",
       " 'انسان',\n",
       " 'دستگاه',\n",
       " 'مشکلات',\n",
       " 'امر',\n",
       " '2',\n",
       " 'انداخت',\n",
       " 'ساخت',\n",
       " 'ارائه',\n",
       " 'هزینه',\n",
       " 'جهان',\n",
       " 'فرهنگ',\n",
       " 'مشاور',\n",
       " 'برنامه\\u200cریزی',\n",
       " 'لازم',\n",
       " 'تربیت',\n",
       " 'آمد',\n",
       " 'نماینده',\n",
       " 'هسته',\n",
       " 'رشد',\n",
       " 'مرکزی',\n",
       " 'مطرح',\n",
       " 'پایان',\n",
       " 'به\\u200cطور',\n",
       " 'مشکل',\n",
       " 'نقش',\n",
       " 'علم',\n",
       " 'بودجه',\n",
       " 'خبرگزاری',\n",
       " 'رییس',\n",
       " 'تلاش',\n",
       " 'رعایت',\n",
       " 'سه',\n",
       " 'تمدن',\n",
       " 'بیمار',\n",
       " 'ایرانی',\n",
       " 'مشخص',\n",
       " 'دنبال',\n",
       " 'اساس',\n",
       " 'کاهش',\n",
       " 'مناطق',\n",
       " 'شکل',\n",
       " 'خاطرنشان',\n",
       " 'اقتصاد',\n",
       " 'جمهوری',\n",
       " 'تراکم',\n",
       " 'می\\u200cتوان',\n",
       " 'دنیا',\n",
       " 'جمعیت',\n",
       " 'جمله',\n",
       " 'قرارداد',\n",
       " 'خانواده',\n",
       " 'مرحله',\n",
       " '1',\n",
       " 'هدف',\n",
       " 'عرصه',\n",
       " 'نشست',\n",
       " 'حرکت',\n",
       " 'تغییر',\n",
       " 'مفهوم',\n",
       " 'سخن',\n",
       " 'استان',\n",
       " 'کمک',\n",
       " 'آموزش',\n",
       " 'شهردار',\n",
       " 'مطالعات',\n",
       " 'زیادی',\n",
       " 'مناسب',\n",
       " '20',\n",
       " 'دانشجویی',\n",
       " 'فدراسیون',\n",
       " 'نفر',\n",
       " 'مصرف',\n",
       " 'انتخابات',\n",
       " 'اثر',\n",
       " 'جام',\n",
       " 'فروش',\n",
       " 'رویاند',\n",
       " 'برد',\n",
       " 'مرکز',\n",
       " 'اصلی',\n",
       " '5',\n",
       " 'مربوط',\n",
       " 'وضعیت',\n",
       " 'حل',\n",
       " 'باعث',\n",
       " 'درآمد',\n",
       " ')،',\n",
       " 'بدنی',\n",
       " 'اقدام',\n",
       " 'ارتباط',\n",
       " 'نهاد',\n",
       " 'امکان',\n",
       " 'تعیین',\n",
       " 'مالی',\n",
       " '3',\n",
       " 'اهداف',\n",
       " 'سوال',\n",
       " 'فرصت',\n",
       " 'مشارکت',\n",
       " 'استقلال',\n",
       " 'حمایت',\n",
       " 'وارد',\n",
       " 'آب',\n",
       " 'تهیه',\n",
       " 'هم\\u200cچنین',\n",
       " 'زمین',\n",
       " '4',\n",
       " 'سیستم',\n",
       " 'سطح',\n",
       " 'آغاز',\n",
       " 'گردشگری',\n",
       " 'ورزش',\n",
       " 'گذاشت',\n",
       " 'حکومت',\n",
       " 'نیرو',\n",
       " 'جنگ',\n",
       " 'آزادی',\n",
       " 'دولتی',\n",
       " 'بهره\\u200cوری',\n",
       " 'پرسپولیس',\n",
       " 'دوره',\n",
       " 'بین\\u200cالمللی',\n",
       " 'پیروزی',\n",
       " 'خصوص',\n",
       " 'اطلاعات',\n",
       " 'تامین',\n",
       " 'منظور',\n",
       " 'معنا',\n",
       " 'دارای',\n",
       " 'دور',\n",
       " 'آسیب',\n",
       " 'طبیعی',\n",
       " 'سرمایه\\u200cگذاری',\n",
       " '10',\n",
       " 'جلسه',\n",
       " 'تشکل',\n",
       " 'پیشرفت',\n",
       " 'واقع',\n",
       " '.»',\n",
       " 'قدرت',\n",
       " 'بسیج',\n",
       " 'تشکیل',\n",
       " 'طول',\n",
       " 'تاریخ',\n",
       " 'مجموعه',\n",
       " 'احزاب',\n",
       " 'رسانه',\n",
       " 'متر',\n",
       " 'شروع',\n",
       " 'راستا',\n",
       " 'کاری',\n",
       " 'جایگاه',\n",
       " 'ارزش',\n",
       " 'شهرداری',\n",
       " 'فعال',\n",
       " 'ترویج',\n",
       " 'فرمود',\n",
       " 'اصل',\n",
       " 'یهودی',\n",
       " 'اختلال',\n",
       " 'اساسی',\n",
       " 'رییس\\u200cجمهور',\n",
       " 'واحد',\n",
       " 'تصمیم',\n",
       " 'ساز',\n",
       " 'تحقق',\n",
       " 'خوبی',\n",
       " 'چشم',\n",
       " 'موجود',\n",
       " 'زندگی',\n",
       " 'اعتقاد',\n",
       " 'خاص',\n",
       " 'معاون',\n",
       " 'اختیار',\n",
       " 'مسیر',\n",
       " 'اصلاح',\n",
       " 'تصویب',\n",
       " 'پیشگیری',\n",
       " 'بازار',\n",
       " 'گاز',\n",
       " 'مهندس',\n",
       " 'تعداد',\n",
       " '6',\n",
       " 'دانش\\u200cآموز',\n",
       " 'سمت',\n",
       " 'سرمایه',\n",
       " 'رای',\n",
       " 'اهمیت',\n",
       " 'انتخاب',\n",
       " 'رویکرد',\n",
       " 'کرمانشاه',\n",
       " 'لیگ',\n",
       " 'مشترک',\n",
       " 'عمل\\u200cکرد',\n",
       " 'تجربه',\n",
       " 'فرد',\n",
       " 'وزارت',\n",
       " 'شهری',\n",
       " 'صنعت',\n",
       " 'جمع',\n",
       " 'الگو',\n",
       " 'پرسش',\n",
       " 'خصوصی',\n",
       " 'یارانه',\n",
       " 'خارج',\n",
       " 'موجب',\n",
       " 'نوشت',\n",
       " 'همراه',\n",
       " 'اعتبارات',\n",
       " 'فراهم',\n",
       " 'اعتبار',\n",
       " 'شهرسازی',\n",
       " 'راهبردی',\n",
       " 'ره',\n",
       " 'فنی',\n",
       " 'رساند',\n",
       " 'شناخت',\n",
       " 'وظیفه',\n",
       " 'طراحی',\n",
       " 'اعتماد',\n",
       " 'نقد',\n",
       " 'خدا',\n",
       " 'سفر',\n",
       " 'ریال',\n",
       " 'بیماری',\n",
       " 'علت',\n",
       " 'رژیم',\n",
       " 'قانونی',\n",
       " 'تسهیلات',\n",
       " 'تعریف',\n",
       " 'اجرایی',\n",
       " 'ظرفیت',\n",
       " 'خارجی',\n",
       " 'اخلاق',\n",
       " 'فضایی',\n",
       " 'حاصل',\n",
       " 'افت',\n",
       " 'ابتدا',\n",
       " 'آزاد',\n",
       " 'مسکن',\n",
       " 'ساله',\n",
       " 'ورزشی',\n",
       " 'این\\u200cگونه',\n",
       " 'دریافت',\n",
       " 'خدمت',\n",
       " 'نامه',\n",
       " 'مبارک',\n",
       " 'رفتار',\n",
       " 'خاطر',\n",
       " 'تاثیر',\n",
       " 'کسب',\n",
       " 'منصوری',\n",
       " 'اندیشه',\n",
       " 'سلول',\n",
       " 'رهیافت',\n",
       " 'برخورد',\n",
       " 'اسناد',\n",
       " 'انتقال',\n",
       " 'عدالت',\n",
       " 'هفته',\n",
       " 'نتایج',\n",
       " 'ایستگاه',\n",
       " 'نظریه',\n",
       " ':«',\n",
       " 'اضافه',\n",
       " 'روند',\n",
       " 'خبر',\n",
       " 'دیدگاه',\n",
       " 'دوران',\n",
       " 'ارایه',\n",
       " 'میدان',\n",
       " 'بانکی',\n",
       " 'جبهه',\n",
       " 'جدی',\n",
       " 'علاوه',\n",
       " 'محیط',\n",
       " 'پرورش',\n",
       " 'پذیرفت',\n",
       " 'محترم',\n",
       " 'نمونه',\n",
       " 'برق',\n",
       " 'تبدیل',\n",
       " 'تحقیقات',\n",
       " 'زد',\n",
       " 'فصل',\n",
       " 'پول',\n",
       " 'نظارت',\n",
       " 'مسوولیت',\n",
       " 'سود',\n",
       " 'پایین',\n",
       " 'اجازه',\n",
       " 'زن',\n",
       " 'محقق',\n",
       " 'شامل',\n",
       " 'تایید',\n",
       " 'ارزیابی',\n",
       " 'فلسطین',\n",
       " 'وزیر',\n",
       " 'هماهنگی',\n",
       " '15',\n",
       " 'گسترش',\n",
       " 'موفقیت',\n",
       " '8',\n",
       " '7',\n",
       " 'معادل',\n",
       " 'رهبری',\n",
       " 'صهیونیسم',\n",
       " 'بازدید',\n",
       " 'مادر',\n",
       " 'پیشنهاد',\n",
       " 'حد',\n",
       " 'غرب',\n",
       " 'تخصصی',\n",
       " 'فرآیند',\n",
       " 'منافع',\n",
       " 'قبول',\n",
       " 'انجمن',\n",
       " 'نمی\\u200cتوان',\n",
       " 'عین',\n",
       " 'مصوبات',\n",
       " 'ساعت',\n",
       " 'روشن',\n",
       " 'وظایف',\n",
       " 'صنفی',\n",
       " 'هولوکاست',\n",
       " 'آسیا',\n",
       " '...',\n",
       " 'فشار',\n",
       " 'تدوین',\n",
       " 'احساس',\n",
       " 'استاد',\n",
       " 'جوان',\n",
       " 'حرف',\n",
       " 'دفتر',\n",
       " 'علی',\n",
       " 'مربی',\n",
       " 'برگزار',\n",
       " 'چهارم',\n",
       " 'سرویس',\n",
       " 'سیگنال',\n",
       " 'خواند',\n",
       " 'خوان',\n",
       " 'درمان',\n",
       " 'انسانی',\n",
       " 'دعوت',\n",
       " 'صحبت',\n",
       " 'می\\u200cگویند',\n",
       " 'مسلمان',\n",
       " 'پژوهشگاه',\n",
       " 'پیگیری',\n",
       " 'شهید',\n",
       " 'امکانات',\n",
       " 'تحقیق',\n",
       " 'ماند',\n",
       " 'امنیت',\n",
       " 'افتاد',\n",
       " 'نکته',\n",
       " 'قالب',\n",
       " 'رقابت',\n",
       " 'کنترل',\n",
       " 'برگزاری',\n",
       " 'دانش',\n",
       " 'ابعاد',\n",
       " 'اتفاق',\n",
       " 'کارشناس',\n",
       " 'مطالعه',\n",
       " 'ضرورت',\n",
       " 'کارگاه',\n",
       " 'کمیته',\n",
       " 'حقیقت',\n",
       " 'کتاب',\n",
       " 'جدول',\n",
       " 'موتلفه',\n",
       " 'اتمی',\n",
       " 'قوانین',\n",
       " 'حادثه',\n",
       " 'امید',\n",
       " 'دستور',\n",
       " 'وقت',\n",
       " 'مبنی',\n",
       " 'دفاع',\n",
       " 'رسیدن',\n",
       " 'محصول',\n",
       " 'پایه',\n",
       " 'اعتباری',\n",
       " 'پژوهشکده',\n",
       " 'آموزشی',\n",
       " 'همکاری',\n",
       " 'خودکشی',\n",
       " 'گرد',\n",
       " 'حقوق',\n",
       " 'اختلاف',\n",
       " 'طبق',\n",
       " 'حفظ']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d9ba578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 501)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4288ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "for row in test.loc[:].values :\n",
    "    text = row[0]\n",
    "    label = row[1] \n",
    "    words = tokenizer.tokenize_words(text) \n",
    "    new_record = {token : words.count(token) for token in token_keys}\n",
    "    new_record.update({'label':label})\n",
    "    test_vectors.append(new_record)\n",
    "    \n",
    "test_vectors = pd.DataFrame.from_dict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d23113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 501)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b30c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test , y_train,y_test = train_test_split(train_vectors.drop('label',axis=1), train_vectors.label, test_size=0.3 , \\\n",
    "                                                  random_state=101, stratify=train_vectors.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e9da9",
   "metadata": {},
   "source": [
    "# Using Multinomial Naive Bayes for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0bdf44b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48339260",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c43b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   economics       0.50      0.50      0.50         2\n",
      "    politics       0.67      0.67      0.67         3\n",
      "    religion       1.00      1.00      1.00         2\n",
      "      social       1.00      0.67      0.80         3\n",
      "       sport       1.00      1.00      1.00         2\n",
      "   strategic       1.00      0.50      0.67         2\n",
      "  technology       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.82      0.76      0.77        17\n",
      "weighted avg       0.81      0.76      0.76        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c50c1deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 2, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c25a683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e046ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04b67b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7690476190476191"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078b891",
   "metadata": {},
   "source": [
    "# Using KNN algorithm for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd23179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "accuracy = 0.35294117647058826\n",
      "recall = 0.35714285714285715\n",
      "f1_score = 0.2891156462585034\n",
      "[[0 0 0 1 0 0 1]\n",
      " [2 0 1 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 0 2 0 0 1]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 0 0 2 0 0 1]]\n",
      "----------\n",
      "K = 3\n",
      "accuracy = 0.35294117647058826\n",
      "recall = 0.38095238095238093\n",
      "f1_score = 0.3129251700680272\n",
      "[[1 0 0 1 0 0 0]\n",
      " [2 0 1 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [1 0 0 1 0 0 1]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 0 0 2 0 0 1]]\n",
      "----------\n",
      "K = 5\n",
      "accuracy = 0.47058823529411764\n",
      "recall = 0.47619047619047616\n",
      "f1_score = 0.4111111111111111\n",
      "[[1 0 1 0 0 0 0]\n",
      " [0 0 2 0 0 0 1]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 1 1 0 0 1]\n",
      " [0 0 0 0 1 0 1]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 3]]\n",
      "----------\n",
      "K = 15\n",
      "accuracy = 0.23529411764705882\n",
      "recall = 0.21428571428571427\n",
      "f1_score = 0.14035087719298245\n",
      "[[0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 3]\n",
      " [0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 3]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ks = [1,3,5,15]\n",
    "for k in ks:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k ,weights='distance',)\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    print(f'K = {k}')\n",
    "    print(f'accuracy = {accuracy_score(y_test,y_pred)}')\n",
    "    print(f\"recall = {recall_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"f1_score = {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50929591",
   "metadata": {},
   "source": [
    "# Calculating TF-IDF for tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "069b273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_tokens = defaultdict(int)\n",
    "num_of_all_texts = train.shape[0] + test.shape[0]\n",
    "for key,value in tokens.items() :\n",
    "    idf = sum(train.text.apply(lambda text : 1 if key in text else 0 ))\n",
    "    idf += sum(test.text.apply(lambda text : 1 if key in text else 0 ))\n",
    "    idf = math.log10(num_of_all_texts / idf)\n",
    "    \n",
    "    idf_tokens[key] =  idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "466c7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_by_tfidf (vector) :\n",
    "    l = []\n",
    "    for key, value in zip(vector.index,vector.values) :\n",
    "        l.append(value * idf_tokens[key])\n",
    "    \n",
    "    return l\n",
    "\n",
    "\n",
    "train_labels = train_vectors.label\n",
    "train_vectors = pd.DataFrame.from_records(train_vectors.drop('label',axis=1).apply(replace_by_tfidf,axis=1), columns= list(train_vectors.columns).remove('label'))\n",
    "train_vectors['label'] = train_labels\n",
    "\n",
    "test_labels = test_vectors.label\n",
    "test_vectors = pd.DataFrame.from_records(test_vectors.drop('label', axis=1).apply(replace_by_tfidf, axis=1), columns = list(test_vectors.columns).remove('label'))\n",
    "test_vectors['label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d158376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test ,y_trian,y_test = train_test_split(train_vectors.drop('label', axis=1), train_vectors.label, test_size=0.3, \\\n",
    "                                                 random_state=101, stratify=train_vectors.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "017895ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "accuracy = 0.47058823529411764\n",
      "recall = 0.4761904761904762\n",
      "f1_score = 0.3992673992673993\n",
      "[[0 0 0 1 0 0 1]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 2 0 0]\n",
      " [0 0 0 1 0 0 1]\n",
      " [0 0 0 2 0 0 1]]\n",
      "----------\n",
      "K = 3\n",
      "accuracy = 0.35294117647058826\n",
      "recall = 0.38095238095238093\n",
      "f1_score = 0.35986394557823126\n",
      "[[1 0 1 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 2 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 0 2 0 0 0 1]]\n",
      "----------\n",
      "K = 5\n",
      "accuracy = 0.29411764705882354\n",
      "recall = 0.33333333333333337\n",
      "f1_score = 0.2857142857142857\n",
      "[[1 0 1 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 0 2 0 0 0 1]]\n",
      "----------\n",
      "K = 15\n",
      "accuracy = 0.35294117647058826\n",
      "recall = 0.40476190476190477\n",
      "f1_score = 0.3360544217687075\n",
      "[[2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0]\n",
      " [2 0 0 0 0 0 1]\n",
      " [0 0 0 0 2 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 1]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ks = [1,3,5,15]\n",
    "for k in ks:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k )\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    print(f'K = {k}')\n",
    "    print(f'accuracy = {accuracy_score(y_test,y_pred)}')\n",
    "    print(f\"recall = {recall_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"f1_score = {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b564e69",
   "metadata": {},
   "source": [
    "If set remove_stop_words parameter to **True** in *normalize_text* method we can see that performance of both KNN and naive bayes models will increase!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
